# -*- coding: utf-8 -*-
"""predict.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qSabA5_M0SBCvZHAzqGkrjuN7jrecKIV
"""

# predict_emission.py

import joblib
import numpy as np
import pandas as pd
from google.colab import drive

drive.mount('/content/drive', force_remount=True)

# Load model, scaler, and features
model = joblib.load('/content/drive/MyDrive/ML-Math-Summative/waste_emission_model.pkl')
scaler = joblib.load('/content/drive/MyDrive/ML-Math-Summative/scaler.pkl')
features = joblib.load('/content/drive/MyDrive/ML-Math-Summative/selected_features.pkl')

def predict_emission(organic_waste, population, gdp_per_capita, landfill, waste_per_capita):
    """Predict methane emissions from waste composition and country data"""
    # Create input dictionary with keys matching training features
    input_dict = {
        'composition_food_organic_waste_percent': organic_waste,
        'population_population_number_of_people': population,
        'gdp': gdp_per_capita,
        'waste_treatment_landfill_unspecified_percent': landfill,
        'waste_generation_per_capita_kg_per_person_per_day': waste_per_capita
    }

    # Convert to DataFrame and scale
    input_df = pd.DataFrame([input_dict])
    input_df = input_df[features]
    scaled_data = scaler.transform(input_df)

    # Make prediction
    prediction = model.predict(scaled_data)
    return prediction[0]

# Example usage
if __name__ == "__main__":
    emission = predict_emission(
        organic_waste=45.6,
        population=5000000,
        gdp_per_capita=2500,
        landfill=30.0,
        waste_per_capita=0.8
    )
    print(f"Predicted methane emissions: {emission:.2f} metric tons CO2 equivalent")